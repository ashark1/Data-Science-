{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Case Study 1.ipynb",
      "provenance": [
        {
          "file_id": "19hBqJA652I0aZ-brcSXA0NIh3hegAS5y",
          "timestamp": 1615567896507
        }
      ]
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "#Using Machine Learning Model on Home Equity Line Of Credit(HELOC) Dataset#",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "import warnings\nwarnings.filterwarnings('ignore')",
      "metadata": {
        "id": "Bw1uPwXVRwqY",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1637763238992,
          "user_tz": 0,
          "elapsed": 232,
          "user": {
            "displayName": "Epaminondas Kapetanios",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4GwAvDdKDidbsCsl9_jIJUxWhpw38t2VmMVy_Q=s64",
            "userId": "17565203717351331319"
          }
        }
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nimport tensorflow as tf",
      "metadata": {
        "id": "Fsu4ibnaRwqZ",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1637763243511,
          "user_tz": 0,
          "elapsed": 1739,
          "user": {
            "displayName": "Epaminondas Kapetanios",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4GwAvDdKDidbsCsl9_jIJUxWhpw38t2VmMVy_Q=s64",
            "userId": "17565203717351331319"
          }
        }
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": "from keras.models import Sequential, Model, load_model, model_from_json\nfrom keras.layers import Dense",
      "metadata": {
        "id": "FwTyvJnGRwqb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1637763247161,
          "user_tz": 0,
          "elapsed": 232,
          "user": {
            "displayName": "Epaminondas Kapetanios",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4GwAvDdKDidbsCsl9_jIJUxWhpw38t2VmMVy_Q=s64",
            "userId": "17565203717351331319"
          }
        },
        "outputId": "84584504-f74f-4c08-e3b1-a7687297dceb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nfrom IPython.core.display import display, HTML",
      "metadata": {
        "id": "djQPEwaPRwqc",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1637763249482,
          "user_tz": 0,
          "elapsed": 225,
          "user": {
            "displayName": "Epaminondas Kapetanios",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4GwAvDdKDidbsCsl9_jIJUxWhpw38t2VmMVy_Q=s64",
            "userId": "17565203717351331319"
          }
        }
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": "!pip install aix360",
      "metadata": {
        "id": "tZaC-721SQvA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1637763256133,
          "user_tz": 0,
          "elapsed": 4198,
          "user": {
            "displayName": "Epaminondas Kapetanios",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4GwAvDdKDidbsCsl9_jIJUxWhpw38t2VmMVy_Q=s64",
            "userId": "17565203717351331319"
          }
        },
        "outputId": "9a370258-4df3-45e5-f9eb-b4b571b01f60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: aix360 in /usr/local/lib/python3.7/dist-packages (0.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from aix360) (2.23.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from aix360) (1.10.0+cu111)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from aix360) (1.1.0)\n",
            "Requirement already satisfied: lime==0.1.1.37 in /usr/local/lib/python3.7/dist-packages (from aix360) (0.1.1.37)\n",
            "Requirement already satisfied: xgboost==1.0.2 in /usr/local/lib/python3.7/dist-packages (from aix360) (1.0.2)\n",
            "Requirement already satisfied: bleach>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from aix360) (4.1.0)\n",
            "Requirement already satisfied: cvxpy in /usr/local/lib/python3.7/dist-packages (from aix360) (1.0.31)\n",
            "Requirement already satisfied: shap==0.34.0 in /usr/local/lib/python3.7/dist-packages (from aix360) (0.34.0)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.7/dist-packages (from aix360) (1.4.1)\n",
            "Requirement already satisfied: docutils>=0.13.1 in /usr/local/lib/python3.7/dist-packages (from aix360) (0.17.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from aix360) (0.18.3)\n",
            "Requirement already satisfied: xport in /usr/local/lib/python3.7/dist-packages (from aix360) (3.2.1)\n",
            "Requirement already satisfied: cvxopt in /usr/local/lib/python3.7/dist-packages (from aix360) (1.2.7)\n",
            "Requirement already satisfied: keras==2.3.1 in /usr/local/lib/python3.7/dist-packages (from aix360) (2.3.1)\n",
            "Requirement already satisfied: qpsolvers in /usr/local/lib/python3.7/dist-packages (from aix360) (1.7.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from aix360) (0.11.1+cu111)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from aix360) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from aix360) (1.21.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.2 in /usr/local/lib/python3.7/dist-packages (from aix360) (1.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from aix360) (1.1.5)\n",
            "Requirement already satisfied: tensorflow==1.14 in /usr/local/lib/python3.7/dist-packages (from aix360) (1.14.0)\n",
            "Requirement already satisfied: Pygments in /usr/local/lib/python3.7/dist-packages (from aix360) (2.6.1)\n",
            "Requirement already satisfied: Image in /usr/local/lib/python3.7/dist-packages (from aix360) (1.5.33)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1->aix360) (3.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1->aix360) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1->aix360) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1->aix360) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1->aix360) (1.1.2)\n",
            "Requirement already satisfied: progressbar in /usr/local/lib/python3.7/dist-packages (from lime==0.1.1.37->aix360) (2.5)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap==0.34.0->aix360) (4.62.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14->aix360) (0.37.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14->aix360) (1.14.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14->aix360) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14->aix360) (0.4.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14->aix360) (0.8.1)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14->aix360) (1.14.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14->aix360) (3.17.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14->aix360) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14->aix360) (1.13.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14->aix360) (0.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14->aix360) (1.42.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach>=2.1.0->aix360) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach>=2.1.0->aix360) (21.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->aix360) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->aix360) (1.2.0)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->aix360) (7.1.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->aix360) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->aix360) (2.6.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aix360) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aix360) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aix360) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aix360) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.2->aix360) (3.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14->aix360) (3.3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14->aix360) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14->aix360) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14->aix360) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14->aix360) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14->aix360) (3.10.0.2)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from cvxpy->aix360) (0.6.2.post0)\n",
            "Requirement already satisfied: scs>=1.1.3 in /usr/local/lib/python3.7/dist-packages (from cvxpy->aix360) (2.1.4)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from cvxpy->aix360) (0.70.12.2)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.7/dist-packages (from cvxpy->aix360) (2.0.7.post1)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.7/dist-packages (from osqp>=0.4.1->cvxpy->aix360) (0.1.5.post0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.3.1->aix360) (1.5.2)\n",
            "Requirement already satisfied: django in /usr/local/lib/python3.7/dist-packages (from Image->aix360) (3.2.9)\n",
            "Requirement already satisfied: asgiref<4,>=3.3.2 in /usr/local/lib/python3.7/dist-packages (from django->Image->aix360) (3.4.1)\n",
            "Requirement already satisfied: sqlparse>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from django->Image->aix360) (0.4.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from django->Image->aix360) (2018.9)\n",
            "Requirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.7/dist-packages (from multiprocess->cvxpy->aix360) (0.3.4)\n",
            "Requirement already satisfied: quadprog>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from qpsolvers->aix360) (0.1.10)\n",
            "Requirement already satisfied: Cython>=0.29.22 in /usr/local/lib/python3.7/dist-packages (from qpsolvers->aix360) (0.29.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->aix360) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->aix360) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->aix360) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->aix360) (2021.10.8)\n",
            "Requirement already satisfied: click>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from xport->aix360) (7.1.2)\n"
          ]
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": "from aix360.algorithms.contrastive import CEMExplainer, KerasClassifier\nfrom aix360.algorithms.protodash import ProtodashExplainer\nfrom aix360.datasets.heloc_dataset import HELOCDataset",
      "metadata": {
        "id": "Cpj_kfWxRwqc",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1637763277784,
          "user_tz": 0,
          "elapsed": 8445,
          "user": {
            "displayName": "Epaminondas Kapetanios",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4GwAvDdKDidbsCsl9_jIJUxWhpw38t2VmMVy_Q=s64",
            "userId": "17565203717351331319"
          }
        }
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": "If you see an error message about the missing data, then you must upload the heloc_data.cvs file into the folder /usr/local/lib/python3.7/dist-packages/aix360/datasets/../data/heloc_data",
      "metadata": {
        "id": "mHucQKxxVA9v"
      }
    },
    {
      "cell_type": "code",
      "source": "heloc = HELOCDataset()\ndf = heloc.dataframe()\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 24)\npd.set_option('display.width', 1000)",
      "metadata": {
        "id": "cEAVi-peRwqd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1637763761554,
          "user_tz": 0,
          "elapsed": 380,
          "user": {
            "displayName": "Epaminondas Kapetanios",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4GwAvDdKDidbsCsl9_jIJUxWhpw38t2VmMVy_Q=s64",
            "userId": "17565203717351331319"
          }
        },
        "outputId": "2ae35b3e-2ab3-4fcd-8d46-ef6531535ce3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Heloc dataset:  /usr/local/lib/python3.7/dist-packages/aix360/datasets/../data/heloc_data/heloc_dataset.csv\n"
          ]
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": "df.head(10).transpose()",
      "metadata": {
        "id": "ifplLIA-Rwqf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1637763889867,
          "user_tz": 0,
          "elapsed": 354,
          "user": {
            "displayName": "Epaminondas Kapetanios",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4GwAvDdKDidbsCsl9_jIJUxWhpw38t2VmMVy_Q=s64",
            "userId": "17565203717351331319"
          }
        },
        "outputId": "54e8c4db-9654-423e-be5e-cc509fc75314"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ExternalRiskEstimate</th>\n",
              "      <td>55</td>\n",
              "      <td>61</td>\n",
              "      <td>67</td>\n",
              "      <td>66</td>\n",
              "      <td>81</td>\n",
              "      <td>59</td>\n",
              "      <td>54</td>\n",
              "      <td>68</td>\n",
              "      <td>59</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSinceOldestTradeOpen</th>\n",
              "      <td>144</td>\n",
              "      <td>58</td>\n",
              "      <td>66</td>\n",
              "      <td>169</td>\n",
              "      <td>333</td>\n",
              "      <td>137</td>\n",
              "      <td>88</td>\n",
              "      <td>148</td>\n",
              "      <td>324</td>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSinceMostRecentTradeOpen</th>\n",
              "      <td>4</td>\n",
              "      <td>15</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AverageMInFile</th>\n",
              "      <td>84</td>\n",
              "      <td>41</td>\n",
              "      <td>24</td>\n",
              "      <td>73</td>\n",
              "      <td>132</td>\n",
              "      <td>78</td>\n",
              "      <td>37</td>\n",
              "      <td>65</td>\n",
              "      <td>138</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumSatisfactoryTrades</th>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>28</td>\n",
              "      <td>12</td>\n",
              "      <td>31</td>\n",
              "      <td>25</td>\n",
              "      <td>17</td>\n",
              "      <td>24</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumTrades60Ever2DerogPubRec</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumTrades90Ever2DerogPubRec</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PercentTradesNeverDelq</th>\n",
              "      <td>83</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>93</td>\n",
              "      <td>100</td>\n",
              "      <td>91</td>\n",
              "      <td>92</td>\n",
              "      <td>83</td>\n",
              "      <td>85</td>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSinceMostRecentDelq</th>\n",
              "      <td>2</td>\n",
              "      <td>-7</td>\n",
              "      <td>-7</td>\n",
              "      <td>76</td>\n",
              "      <td>-7</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>31</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MaxDelq2PublicRecLast12M</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MaxDelqEver</th>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumTotalTrades</th>\n",
              "      <td>23</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>30</td>\n",
              "      <td>12</td>\n",
              "      <td>32</td>\n",
              "      <td>26</td>\n",
              "      <td>18</td>\n",
              "      <td>27</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumTradesOpeninLast12M</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PercentInstallTrades</th>\n",
              "      <td>43</td>\n",
              "      <td>67</td>\n",
              "      <td>44</td>\n",
              "      <td>57</td>\n",
              "      <td>25</td>\n",
              "      <td>47</td>\n",
              "      <td>58</td>\n",
              "      <td>44</td>\n",
              "      <td>26</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSinceMostRecentInqexcl7days</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumInqLast6M</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumInqLast6Mexcl7days</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NetFractionRevolvingBurden</th>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>53</td>\n",
              "      <td>72</td>\n",
              "      <td>51</td>\n",
              "      <td>62</td>\n",
              "      <td>89</td>\n",
              "      <td>28</td>\n",
              "      <td>68</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NetFractionInstallBurden</th>\n",
              "      <td>-8</td>\n",
              "      <td>-8</td>\n",
              "      <td>66</td>\n",
              "      <td>83</td>\n",
              "      <td>89</td>\n",
              "      <td>93</td>\n",
              "      <td>76</td>\n",
              "      <td>48</td>\n",
              "      <td>-8</td>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumRevolvingTradesWBalance</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumInstallTradesWBalance</th>\n",
              "      <td>1</td>\n",
              "      <td>-8</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumBank2NatlTradesWHighUtilization</th>\n",
              "      <td>1</td>\n",
              "      <td>-8</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PercentTradesWBalance</th>\n",
              "      <td>69</td>\n",
              "      <td>0</td>\n",
              "      <td>86</td>\n",
              "      <td>91</td>\n",
              "      <td>80</td>\n",
              "      <td>94</td>\n",
              "      <td>100</td>\n",
              "      <td>40</td>\n",
              "      <td>90</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RiskPerformance</th>\n",
              "      <td>Bad</td>\n",
              "      <td>Bad</td>\n",
              "      <td>Bad</td>\n",
              "      <td>Bad</td>\n",
              "      <td>Bad</td>\n",
              "      <td>Bad</td>\n",
              "      <td>Good</td>\n",
              "      <td>Good</td>\n",
              "      <td>Bad</td>\n",
              "      <td>Bad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      0    1    2    3    4    5     6     7    8    9\n",
              "ExternalRiskEstimate                 55   61   67   66   81   59    54    68   59   61\n",
              "MSinceOldestTradeOpen               144   58   66  169  333  137    88   148  324   79\n",
              "MSinceMostRecentTradeOpen             4   15    5    1   27   11     7     7    2    4\n",
              "AverageMInFile                       84   41   24   73  132   78    37    65  138   36\n",
              "NumSatisfactoryTrades                20    2    9   28   12   31    25    17   24   19\n",
              "NumTrades60Ever2DerogPubRec           3    4    0    1    0    0     0     0    0    0\n",
              "NumTrades90Ever2DerogPubRec           0    4    0    1    0    0     0     0    0    0\n",
              "PercentTradesNeverDelq               83  100  100   93  100   91    92    83   85   95\n",
              "MSinceMostRecentDelq                  2   -7   -7   76   -7    1     9    31    5    5\n",
              "MaxDelq2PublicRecLast12M              3    0    7    6    7    4     4     6    4    4\n",
              "MaxDelqEver                           5    8    8    6    8    6     6     6    6    6\n",
              "NumTotalTrades                       23    7    9   30   12   32    26    18   27   19\n",
              "NumTradesOpeninLast12M                1    0    4    3    0    1     3     1    1    3\n",
              "PercentInstallTrades                 43   67   44   57   25   47    58    44   26   26\n",
              "MSinceMostRecentInqexcl7days          0    0    0    0    0    0     0     0    0    0\n",
              "NumInqLast6M                          0    0    4    5    1    0     4     0    1    6\n",
              "NumInqLast6Mexcl7days                 0    0    4    4    1    0     4     0    1    6\n",
              "NetFractionRevolvingBurden           33    0   53   72   51   62    89    28   68   31\n",
              "NetFractionInstallBurden             -8   -8   66   83   89   93    76    48   -8   86\n",
              "NumRevolvingTradesWBalance            8    0    4    6    3   12     7     2    7    5\n",
              "NumInstallTradesWBalance              1   -8    2    4    1    4     7     2    1    3\n",
              "NumBank2NatlTradesWHighUtilization    1   -8    1    3    0    3     2     2    3    1\n",
              "PercentTradesWBalance                69    0   86   91   80   94   100    40   90   62\n",
              "RiskPerformance                     Bad  Bad  Bad  Bad  Bad  Bad  Good  Good  Bad  Bad"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": "print(\"Size of HELOC dataset:\", df.shape)\nprint(\"Number of \\\"Good\\\" applicants:\", np.sum(df['RiskPerformance']=='Good'))",
      "metadata": {
        "id": "QZHLKlTpRwqg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1637763923125,
          "user_tz": 0,
          "elapsed": 260,
          "user": {
            "displayName": "Epaminondas Kapetanios",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4GwAvDdKDidbsCsl9_jIJUxWhpw38t2VmMVy_Q=s64",
            "userId": "17565203717351331319"
          }
        },
        "outputId": "0f1882f0-f58b-408e-cdb1-0cc7c6010dc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of HELOC dataset: (10459, 24)\n",
            "Number of \"Good\" applicants: 5000\n"
          ]
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": "print(\"Number of \\\"Bad\\\" applicants:\", np.sum(df['RiskPerformance']=='Bad'))",
      "metadata": {
        "id": "ckswfkUKRwqh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1637763935138,
          "user_tz": 0,
          "elapsed": 240,
          "user": {
            "displayName": "Epaminondas Kapetanios",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4GwAvDdKDidbsCsl9_jIJUxWhpw38t2VmMVy_Q=s64",
            "userId": "17565203717351331319"
          }
        },
        "outputId": "ef2db2af-b863-4826-cccf-30095b301103"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of \"Bad\" applicants: 5459\n"
          ]
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": "hist = df.hist(column=['NumInqLast6M'], bins=40)",
      "metadata": {
        "id": "1BuQp3IDRwqi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1637763938426,
          "user_tz": 0,
          "elapsed": 599,
          "user": {
            "displayName": "Epaminondas Kapetanios",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4GwAvDdKDidbsCsl9_jIJUxWhpw38t2VmMVy_Q=s64",
            "userId": "17565203717351331319"
          }
        },
        "outputId": "4ea41909-f229-4324-d748-5aee95a1f827"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": "(Data, x_train, x_test, y_train_b, y_test_b) = heloc.split()",
      "metadata": {
        "id": "vkphyLgERwqj",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1637763941538,
          "user_tz": 0,
          "elapsed": 242,
          "user": {
            "displayName": "Epaminondas Kapetanios",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4GwAvDdKDidbsCsl9_jIJUxWhpw38t2VmMVy_Q=s64",
            "userId": "17565203717351331319"
          }
        }
      },
      "outputs": [],
      "execution_count": 15
    },
    {
      "cell_type": "code",
      "source": "Z = np.vstack((x_train, x_test))\nZmax = np.max(Z, axis=0)\nZmin = np.min(Z, axis=0)",
      "metadata": {
        "id": "iBjRqqoYRwqk",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1637763944965,
          "user_tz": 0,
          "elapsed": 283,
          "user": {
            "displayName": "Epaminondas Kapetanios",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4GwAvDdKDidbsCsl9_jIJUxWhpw38t2VmMVy_Q=s64",
            "userId": "17565203717351331319"
          }
        }
      },
      "outputs": [],
      "execution_count": 16
    },
    {
      "cell_type": "code",
      "source": "print(Zmin)",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2guOq7U4Rwqk",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1637763947010,
          "user_tz": 0,
          "elapsed": 246,
          "user": {
            "displayName": "Epaminondas Kapetanios",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4GwAvDdKDidbsCsl9_jIJUxWhpw38t2VmMVy_Q=s64",
            "userId": "17565203717351331319"
          }
        },
        "outputId": "94ecefc9-92f1-4366-fd1b-856004879fea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 4 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ],
      "execution_count": 17
    },
    {
      "cell_type": "code",
      "source": "print(Zmax)",
      "metadata": {
        "id": "Lpfyin2iRwql",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1637763949470,
          "user_tz": 0,
          "elapsed": 259,
          "user": {
            "displayName": "Epaminondas Kapetanios",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4GwAvDdKDidbsCsl9_jIJUxWhpw38t2VmMVy_Q=s64",
            "userId": "17565203717351331319"
          }
        },
        "outputId": "7ce0fe52-9253-401a-af7d-49730045cdb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 94 803 383 383  79  19  19 100  83   9   8 104  19 100  24  66  66 232\n",
            " 471  32  23  18 100]\n"
          ]
        }
      ],
      "execution_count": 18
    },
    {
      "cell_type": "code",
      "source": "def normalize(V):\n    VN = (V - Zmin)/(Zmax - Zmin)\n    VN = VN - 0.5\n    return(VN)",
      "metadata": {
        "id": "pFS7tUC8Rwql",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1637763952018,
          "user_tz": 0,
          "elapsed": 238,
          "user": {
            "displayName": "Epaminondas Kapetanios",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4GwAvDdKDidbsCsl9_jIJUxWhpw38t2VmMVy_Q=s64",
            "userId": "17565203717351331319"
          }
        }
      },
      "outputs": [],
      "execution_count": 19
    },
    {
      "cell_type": "code",
      "source": "print(normalize(x_train[3:5]))",
      "metadata": {
        "id": "14rWlDPFRwqm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1637763954881,
          "user_tz": 0,
          "elapsed": 234,
          "user": {
            "displayName": "Epaminondas Kapetanios",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4GwAvDdKDidbsCsl9_jIJUxWhpw38t2VmMVy_Q=s64",
            "userId": "17565203717351331319"
          }
        },
        "outputId": "baa3c7f9-888e-41ad-e6be-14e30be568ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.19148936 -0.21606476 -0.48694517 -0.32849604 -0.19620253 -0.34210526\n",
            "  -0.39473684  0.35       -0.46385542 -0.5        -0.5        -0.24038462\n",
            "  -0.44736842 -0.19       -0.20833333 -0.5        -0.5        -0.44396552\n",
            "  -0.35987261 -0.40625    -0.41304348 -0.5        -0.04      ]\n",
            " [ 0.19148936 -0.35429639 -0.48172324 -0.38390501 -0.41139241 -0.44736842\n",
            "  -0.44736842  0.28       -0.06626506  0.16666667 -0.16666667 -0.41346154\n",
            "  -0.39473684  0.06       -0.20833333 -0.5        -0.5        -0.26724138\n",
            "  -0.35350318 -0.4375     -0.36956522 -0.44444444  0.33      ]]\n"
          ]
        }
      ],
      "execution_count": 20
    },
    {
      "cell_type": "code",
      "source": "N = normalize(Z)\nxn_train = N[0:x_train.shape[0], :]\nxn_test  = N[x_train.shape[0]:, :]",
      "metadata": {
        "id": "IN2WojRoRwqm",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1637763957897,
          "user_tz": 0,
          "elapsed": 235,
          "user": {
            "displayName": "Epaminondas Kapetanios",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4GwAvDdKDidbsCsl9_jIJUxWhpw38t2VmMVy_Q=s64",
            "userId": "17565203717351331319"
          }
        }
      },
      "outputs": [],
      "execution_count": 21
    },
    {
      "cell_type": "code",
      "source": "def nn_small():\n    model = Sequential()\n    model.add(Dense(10, input_dim=23, kernel_initializer='normal', activation='relu'))\n    model.add(Dense(2, kernel_initializer='normal'))    \n    return model",
      "metadata": {
        "id": "2kaac1hVRwqn",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1637763961112,
          "user_tz": 0,
          "elapsed": 240,
          "user": {
            "displayName": "Epaminondas Kapetanios",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4GwAvDdKDidbsCsl9_jIJUxWhpw38t2VmMVy_Q=s64",
            "userId": "17565203717351331319"
          }
        }
      },
      "outputs": [],
      "execution_count": 22
    },
    {
      "cell_type": "code",
      "source": "np.random.seed(1) \ntf.set_random_seed(2) \n\nclass_names = ['Bad', 'Good']",
      "metadata": {
        "id": "uJr1QClvRwqo",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1637763964620,
          "user_tz": 0,
          "elapsed": 237,
          "user": {
            "displayName": "Epaminondas Kapetanios",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4GwAvDdKDidbsCsl9_jIJUxWhpw38t2VmMVy_Q=s64",
            "userId": "17565203717351331319"
          }
        }
      },
      "outputs": [],
      "execution_count": 23
    },
    {
      "cell_type": "code",
      "source": "def fn(correct, predicted):\n    return tf.nn.softmax_cross_entropy_with_logits(labels=correct, logits=predicted)\n",
      "metadata": {
        "id": "U9i5CGEPRwqo",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1637763967022,
          "user_tz": 0,
          "elapsed": 259,
          "user": {
            "displayName": "Epaminondas Kapetanios",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4GwAvDdKDidbsCsl9_jIJUxWhpw38t2VmMVy_Q=s64",
            "userId": "17565203717351331319"
          }
        }
      },
      "outputs": [],
      "execution_count": 24
    },
    {
      "cell_type": "code",
      "source": "nn = nn_small()\nnn.compile(loss=fn, optimizer='adam', metrics=['accuracy'])\nnn.summary()",
      "metadata": {
        "id": "0AuUWDZ3Rwqw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1637763969616,
          "user_tz": 0,
          "elapsed": 264,
          "user": {
            "displayName": "Epaminondas Kapetanios",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4GwAvDdKDidbsCsl9_jIJUxWhpw38t2VmMVy_Q=s64",
            "userId": "17565203717351331319"
          }
        },
        "outputId": "cd2fc446-1545-408c-fe6a-921609ce36fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From <ipython-input-24-ea7df5a704d6>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 10)                240       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 22        \n",
            "=================================================================\n",
            "Total params: 262\n",
            "Trainable params: 262\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "execution_count": 25
    },
    {
      "cell_type": "code",
      "source": "nn.fit(xn_train, y_train_b, batch_size=128, epochs=500, verbose=1, shuffle=False)",
      "metadata": {
        "id": "QtstmDPIRwqw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1637764020226,
          "user_tz": 0,
          "elapsed": 43071,
          "user": {
            "displayName": "Epaminondas Kapetanios",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4GwAvDdKDidbsCsl9_jIJUxWhpw38t2VmMVy_Q=s64",
            "userId": "17565203717351331319"
          }
        },
        "outputId": "57c7fdd5-32d9-4cb8-e30f-3876d8a2a6d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Epoch 1/500\n",
            "7403/7403 [==============================] - 0s 24us/step - loss: 0.6878 - accuracy: 0.5346\n",
            "Epoch 2/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.6640 - accuracy: 0.6416\n",
            "Epoch 3/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.6243 - accuracy: 0.6993\n",
            "Epoch 4/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5931 - accuracy: 0.7092\n",
            "Epoch 5/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5766 - accuracy: 0.7132\n",
            "Epoch 6/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5679 - accuracy: 0.7194\n",
            "Epoch 7/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5627 - accuracy: 0.7219\n",
            "Epoch 8/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5591 - accuracy: 0.7252\n",
            "Epoch 9/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5566 - accuracy: 0.7250\n",
            "Epoch 10/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5546 - accuracy: 0.7266\n",
            "Epoch 11/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5531 - accuracy: 0.7277\n",
            "Epoch 12/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5519 - accuracy: 0.7284\n",
            "Epoch 13/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5509 - accuracy: 0.7279\n",
            "Epoch 14/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5501 - accuracy: 0.7282\n",
            "Epoch 15/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5494 - accuracy: 0.7297\n",
            "Epoch 16/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5488 - accuracy: 0.7306\n",
            "Epoch 17/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5482 - accuracy: 0.7311\n",
            "Epoch 18/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5477 - accuracy: 0.7316\n",
            "Epoch 19/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5473 - accuracy: 0.7320\n",
            "Epoch 20/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5469 - accuracy: 0.7309\n",
            "Epoch 21/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5466 - accuracy: 0.7309\n",
            "Epoch 22/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5463 - accuracy: 0.7312\n",
            "Epoch 23/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5460 - accuracy: 0.7311\n",
            "Epoch 24/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5458 - accuracy: 0.7311\n",
            "Epoch 25/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5455 - accuracy: 0.7313\n",
            "Epoch 26/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5453 - accuracy: 0.7312\n",
            "Epoch 27/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5451 - accuracy: 0.7316\n",
            "Epoch 28/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5449 - accuracy: 0.7315\n",
            "Epoch 29/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5447 - accuracy: 0.7323\n",
            "Epoch 30/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5445 - accuracy: 0.7321\n",
            "Epoch 31/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5443 - accuracy: 0.7327\n",
            "Epoch 32/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5442 - accuracy: 0.7331\n",
            "Epoch 33/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5440 - accuracy: 0.7335\n",
            "Epoch 34/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5439 - accuracy: 0.7334\n",
            "Epoch 35/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5437 - accuracy: 0.7339\n",
            "Epoch 36/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5436 - accuracy: 0.7338\n",
            "Epoch 37/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5435 - accuracy: 0.7342\n",
            "Epoch 38/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5433 - accuracy: 0.7335\n",
            "Epoch 39/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5432 - accuracy: 0.7332\n",
            "Epoch 40/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5431 - accuracy: 0.7328\n",
            "Epoch 41/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5430 - accuracy: 0.7325\n",
            "Epoch 42/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5429 - accuracy: 0.7328\n",
            "Epoch 43/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5428 - accuracy: 0.7338\n",
            "Epoch 44/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5428 - accuracy: 0.7339\n",
            "Epoch 45/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5427 - accuracy: 0.7342\n",
            "Epoch 46/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5426 - accuracy: 0.7344\n",
            "Epoch 47/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5425 - accuracy: 0.7346\n",
            "Epoch 48/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5424 - accuracy: 0.7344\n",
            "Epoch 49/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5424 - accuracy: 0.7343\n",
            "Epoch 50/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5423 - accuracy: 0.7339\n",
            "Epoch 51/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5422 - accuracy: 0.7342\n",
            "Epoch 52/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5421 - accuracy: 0.7339\n",
            "Epoch 53/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5421 - accuracy: 0.7340\n",
            "Epoch 54/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5420 - accuracy: 0.7339\n",
            "Epoch 55/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5420 - accuracy: 0.7339\n",
            "Epoch 56/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5419 - accuracy: 0.7336\n",
            "Epoch 57/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5418 - accuracy: 0.7339\n",
            "Epoch 58/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5418 - accuracy: 0.7342\n",
            "Epoch 59/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5417 - accuracy: 0.7342\n",
            "Epoch 60/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5416 - accuracy: 0.7342\n",
            "Epoch 61/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5416 - accuracy: 0.7344\n",
            "Epoch 62/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5415 - accuracy: 0.7344\n",
            "Epoch 63/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5415 - accuracy: 0.7346\n",
            "Epoch 64/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5414 - accuracy: 0.7346\n",
            "Epoch 65/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5414 - accuracy: 0.7347\n",
            "Epoch 66/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5413 - accuracy: 0.7346\n",
            "Epoch 67/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5413 - accuracy: 0.7350\n",
            "Epoch 68/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5412 - accuracy: 0.7352\n",
            "Epoch 69/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5412 - accuracy: 0.7348\n",
            "Epoch 70/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5411 - accuracy: 0.7346\n",
            "Epoch 71/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5411 - accuracy: 0.7344\n",
            "Epoch 72/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5410 - accuracy: 0.7346\n",
            "Epoch 73/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5410 - accuracy: 0.7347\n",
            "Epoch 74/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5409 - accuracy: 0.7346\n",
            "Epoch 75/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5408 - accuracy: 0.7343\n",
            "Epoch 76/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5408 - accuracy: 0.7344\n",
            "Epoch 77/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5407 - accuracy: 0.7344\n",
            "Epoch 78/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5406 - accuracy: 0.7338\n",
            "Epoch 79/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5406 - accuracy: 0.7336\n",
            "Epoch 80/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5405 - accuracy: 0.7338\n",
            "Epoch 81/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5405 - accuracy: 0.7336\n",
            "Epoch 82/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5404 - accuracy: 0.7339\n",
            "Epoch 83/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5404 - accuracy: 0.7340\n",
            "Epoch 84/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5403 - accuracy: 0.7340\n",
            "Epoch 85/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5402 - accuracy: 0.7342\n",
            "Epoch 86/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5402 - accuracy: 0.7343\n",
            "Epoch 87/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5402 - accuracy: 0.7343\n",
            "Epoch 88/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5401 - accuracy: 0.7342\n",
            "Epoch 89/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5400 - accuracy: 0.7342\n",
            "Epoch 90/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5400 - accuracy: 0.7344\n",
            "Epoch 91/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5399 - accuracy: 0.7347\n",
            "Epoch 92/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5399 - accuracy: 0.7347\n",
            "Epoch 93/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5398 - accuracy: 0.7350\n",
            "Epoch 94/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5398 - accuracy: 0.7346\n",
            "Epoch 95/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5398 - accuracy: 0.7347\n",
            "Epoch 96/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5397 - accuracy: 0.7346\n",
            "Epoch 97/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5397 - accuracy: 0.7344\n",
            "Epoch 98/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5396 - accuracy: 0.7344\n",
            "Epoch 99/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5396 - accuracy: 0.7346\n",
            "Epoch 100/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5395 - accuracy: 0.7347\n",
            "Epoch 101/500\n",
            "7403/7403 [==============================] - 0s 8us/step - loss: 0.5395 - accuracy: 0.7347\n",
            "Epoch 102/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5394 - accuracy: 0.7350\n",
            "Epoch 103/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5394 - accuracy: 0.7351\n",
            "Epoch 104/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5394 - accuracy: 0.7352\n",
            "Epoch 105/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5393 - accuracy: 0.7352\n",
            "Epoch 106/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5393 - accuracy: 0.7351\n",
            "Epoch 107/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5392 - accuracy: 0.7351\n",
            "Epoch 108/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5392 - accuracy: 0.7350\n",
            "Epoch 109/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5391 - accuracy: 0.7350\n",
            "Epoch 110/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5391 - accuracy: 0.7347\n",
            "Epoch 111/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5391 - accuracy: 0.7343\n",
            "Epoch 112/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5390 - accuracy: 0.7342\n",
            "Epoch 113/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5389 - accuracy: 0.7342\n",
            "Epoch 114/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5389 - accuracy: 0.7342\n",
            "Epoch 115/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5388 - accuracy: 0.7342\n",
            "Epoch 116/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5388 - accuracy: 0.7339\n",
            "Epoch 117/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5387 - accuracy: 0.7335\n",
            "Epoch 118/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5387 - accuracy: 0.7338\n",
            "Epoch 119/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5386 - accuracy: 0.7338\n",
            "Epoch 120/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5386 - accuracy: 0.7335\n",
            "Epoch 121/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5385 - accuracy: 0.7338\n",
            "Epoch 122/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5385 - accuracy: 0.7340\n",
            "Epoch 123/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5384 - accuracy: 0.7339\n",
            "Epoch 124/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5384 - accuracy: 0.7336\n",
            "Epoch 125/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5383 - accuracy: 0.7340\n",
            "Epoch 126/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5383 - accuracy: 0.7343\n",
            "Epoch 127/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5382 - accuracy: 0.7340\n",
            "Epoch 128/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5382 - accuracy: 0.7340\n",
            "Epoch 129/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5381 - accuracy: 0.7340\n",
            "Epoch 130/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5381 - accuracy: 0.7342\n",
            "Epoch 131/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5380 - accuracy: 0.7340\n",
            "Epoch 132/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5380 - accuracy: 0.7338\n",
            "Epoch 133/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5380 - accuracy: 0.7340\n",
            "Epoch 134/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5379 - accuracy: 0.7340\n",
            "Epoch 135/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5379 - accuracy: 0.7342\n",
            "Epoch 136/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5378 - accuracy: 0.7343\n",
            "Epoch 137/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5378 - accuracy: 0.7347\n",
            "Epoch 138/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5378 - accuracy: 0.7342\n",
            "Epoch 139/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5377 - accuracy: 0.7344\n",
            "Epoch 140/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5377 - accuracy: 0.7342\n",
            "Epoch 141/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5376 - accuracy: 0.7339\n",
            "Epoch 142/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5376 - accuracy: 0.7339\n",
            "Epoch 143/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5375 - accuracy: 0.7340\n",
            "Epoch 144/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5375 - accuracy: 0.7343\n",
            "Epoch 145/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5374 - accuracy: 0.7342\n",
            "Epoch 146/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5374 - accuracy: 0.7340\n",
            "Epoch 147/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5374 - accuracy: 0.7340\n",
            "Epoch 148/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5373 - accuracy: 0.7344\n",
            "Epoch 149/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5373 - accuracy: 0.7340\n",
            "Epoch 150/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5372 - accuracy: 0.7343\n",
            "Epoch 151/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5372 - accuracy: 0.7347\n",
            "Epoch 152/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5372 - accuracy: 0.7343\n",
            "Epoch 153/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5371 - accuracy: 0.7344\n",
            "Epoch 154/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5371 - accuracy: 0.7346\n",
            "Epoch 155/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5371 - accuracy: 0.7343\n",
            "Epoch 156/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5370 - accuracy: 0.7342\n",
            "Epoch 157/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5370 - accuracy: 0.7342\n",
            "Epoch 158/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5370 - accuracy: 0.7343\n",
            "Epoch 159/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5369 - accuracy: 0.7343\n",
            "Epoch 160/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5369 - accuracy: 0.7342\n",
            "Epoch 161/500\n",
            "7403/7403 [==============================] - 0s 8us/step - loss: 0.5369 - accuracy: 0.7347\n",
            "Epoch 162/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5369 - accuracy: 0.7347\n",
            "Epoch 163/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5368 - accuracy: 0.7348\n",
            "Epoch 164/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5368 - accuracy: 0.7348\n",
            "Epoch 165/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5368 - accuracy: 0.7350\n",
            "Epoch 166/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5368 - accuracy: 0.7348\n",
            "Epoch 167/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5367 - accuracy: 0.7350\n",
            "Epoch 168/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5367 - accuracy: 0.7344\n",
            "Epoch 169/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5367 - accuracy: 0.7343\n",
            "Epoch 170/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5367 - accuracy: 0.7346\n",
            "Epoch 171/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5366 - accuracy: 0.7344\n",
            "Epoch 172/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5366 - accuracy: 0.7343\n",
            "Epoch 173/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5366 - accuracy: 0.7344\n",
            "Epoch 174/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5366 - accuracy: 0.7344\n",
            "Epoch 175/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5366 - accuracy: 0.7344\n",
            "Epoch 176/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5365 - accuracy: 0.7344\n",
            "Epoch 177/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5365 - accuracy: 0.7342\n",
            "Epoch 178/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5365 - accuracy: 0.7342\n",
            "Epoch 179/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5365 - accuracy: 0.7342\n",
            "Epoch 180/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5365 - accuracy: 0.7346\n",
            "Epoch 181/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5364 - accuracy: 0.7346\n",
            "Epoch 182/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5364 - accuracy: 0.7348\n",
            "Epoch 183/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5364 - accuracy: 0.7348\n",
            "Epoch 184/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5364 - accuracy: 0.7348\n",
            "Epoch 185/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5363 - accuracy: 0.7351\n",
            "Epoch 186/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5363 - accuracy: 0.7350\n",
            "Epoch 187/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5363 - accuracy: 0.7348\n",
            "Epoch 188/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5363 - accuracy: 0.7351\n",
            "Epoch 189/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5363 - accuracy: 0.7351\n",
            "Epoch 190/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5362 - accuracy: 0.7354\n",
            "Epoch 191/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5362 - accuracy: 0.7354\n",
            "Epoch 192/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5362 - accuracy: 0.7355\n",
            "Epoch 193/500\n",
            "7403/7403 [==============================] - 0s 13us/step - loss: 0.5362 - accuracy: 0.7355\n",
            "Epoch 194/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5362 - accuracy: 0.7361\n",
            "Epoch 195/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5361 - accuracy: 0.7358\n",
            "Epoch 196/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5361 - accuracy: 0.7355\n",
            "Epoch 197/500\n",
            "7403/7403 [==============================] - 0s 13us/step - loss: 0.5361 - accuracy: 0.7356\n",
            "Epoch 198/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5361 - accuracy: 0.7351\n",
            "Epoch 199/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5361 - accuracy: 0.7355\n",
            "Epoch 200/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5361 - accuracy: 0.7354\n",
            "Epoch 201/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5360 - accuracy: 0.7358\n",
            "Epoch 202/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5360 - accuracy: 0.7351\n",
            "Epoch 203/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5360 - accuracy: 0.7354\n",
            "Epoch 204/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5360 - accuracy: 0.7352\n",
            "Epoch 205/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5360 - accuracy: 0.7359\n",
            "Epoch 206/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5360 - accuracy: 0.7356\n",
            "Epoch 207/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5359 - accuracy: 0.7358\n",
            "Epoch 208/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5359 - accuracy: 0.7356\n",
            "Epoch 209/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5359 - accuracy: 0.7356\n",
            "Epoch 210/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5359 - accuracy: 0.7354\n",
            "Epoch 211/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5359 - accuracy: 0.7356\n",
            "Epoch 212/500\n",
            "7403/7403 [==============================] - 0s 14us/step - loss: 0.5358 - accuracy: 0.7356\n",
            "Epoch 213/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5358 - accuracy: 0.7356\n",
            "Epoch 214/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5358 - accuracy: 0.7355\n",
            "Epoch 215/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5358 - accuracy: 0.7358\n",
            "Epoch 216/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5358 - accuracy: 0.7356\n",
            "Epoch 217/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5358 - accuracy: 0.7358\n",
            "Epoch 218/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5358 - accuracy: 0.7356\n",
            "Epoch 219/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5358 - accuracy: 0.7352\n",
            "Epoch 220/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5357 - accuracy: 0.7351\n",
            "Epoch 221/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5357 - accuracy: 0.7351\n",
            "Epoch 222/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5357 - accuracy: 0.7351\n",
            "Epoch 223/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5357 - accuracy: 0.7350\n",
            "Epoch 224/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5357 - accuracy: 0.7350\n",
            "Epoch 225/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5357 - accuracy: 0.7351\n",
            "Epoch 226/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5357 - accuracy: 0.7352\n",
            "Epoch 227/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5357 - accuracy: 0.7355\n",
            "Epoch 228/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5357 - accuracy: 0.7354\n",
            "Epoch 229/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5356 - accuracy: 0.7352\n",
            "Epoch 230/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5356 - accuracy: 0.7352\n",
            "Epoch 231/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5356 - accuracy: 0.7350\n",
            "Epoch 232/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5356 - accuracy: 0.7350\n",
            "Epoch 233/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5356 - accuracy: 0.7351\n",
            "Epoch 234/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5356 - accuracy: 0.7351\n",
            "Epoch 235/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5356 - accuracy: 0.7350\n",
            "Epoch 236/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5355 - accuracy: 0.7350\n",
            "Epoch 237/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5355 - accuracy: 0.7351\n",
            "Epoch 238/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5355 - accuracy: 0.7347\n",
            "Epoch 239/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5355 - accuracy: 0.7346\n",
            "Epoch 240/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5355 - accuracy: 0.7343\n",
            "Epoch 241/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5354 - accuracy: 0.7344\n",
            "Epoch 242/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5354 - accuracy: 0.7346\n",
            "Epoch 243/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5354 - accuracy: 0.7351\n",
            "Epoch 244/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5354 - accuracy: 0.7351\n",
            "Epoch 245/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5354 - accuracy: 0.7348\n",
            "Epoch 246/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5353 - accuracy: 0.7347\n",
            "Epoch 247/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5353 - accuracy: 0.7350\n",
            "Epoch 248/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5353 - accuracy: 0.7348\n",
            "Epoch 249/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5353 - accuracy: 0.7348\n",
            "Epoch 250/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5352 - accuracy: 0.7350\n",
            "Epoch 251/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5352 - accuracy: 0.7348\n",
            "Epoch 252/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5352 - accuracy: 0.7347\n",
            "Epoch 253/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5352 - accuracy: 0.7350\n",
            "Epoch 254/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5351 - accuracy: 0.7351\n",
            "Epoch 255/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5351 - accuracy: 0.7352\n",
            "Epoch 256/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5351 - accuracy: 0.7356\n",
            "Epoch 257/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5350 - accuracy: 0.7356\n",
            "Epoch 258/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5350 - accuracy: 0.7356\n",
            "Epoch 259/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5349 - accuracy: 0.7356\n",
            "Epoch 260/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5348 - accuracy: 0.7355\n",
            "Epoch 261/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5348 - accuracy: 0.7350\n",
            "Epoch 262/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5347 - accuracy: 0.7352\n",
            "Epoch 263/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5347 - accuracy: 0.7354\n",
            "Epoch 264/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5346 - accuracy: 0.7358\n",
            "Epoch 265/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5346 - accuracy: 0.7362\n",
            "Epoch 266/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5345 - accuracy: 0.7362\n",
            "Epoch 267/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5345 - accuracy: 0.7358\n",
            "Epoch 268/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5344 - accuracy: 0.7358\n",
            "Epoch 269/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5343 - accuracy: 0.7354\n",
            "Epoch 270/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5342 - accuracy: 0.7358\n",
            "Epoch 271/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5341 - accuracy: 0.7358\n",
            "Epoch 272/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5340 - accuracy: 0.7355\n",
            "Epoch 273/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5339 - accuracy: 0.7352\n",
            "Epoch 274/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5339 - accuracy: 0.7354\n",
            "Epoch 275/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5338 - accuracy: 0.7350\n",
            "Epoch 276/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5337 - accuracy: 0.7362\n",
            "Epoch 277/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5336 - accuracy: 0.7362\n",
            "Epoch 278/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5335 - accuracy: 0.7359\n",
            "Epoch 279/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5335 - accuracy: 0.7362\n",
            "Epoch 280/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5334 - accuracy: 0.7361\n",
            "Epoch 281/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5334 - accuracy: 0.7361\n",
            "Epoch 282/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5333 - accuracy: 0.7362\n",
            "Epoch 283/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5333 - accuracy: 0.7358\n",
            "Epoch 284/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5332 - accuracy: 0.7359\n",
            "Epoch 285/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5332 - accuracy: 0.7355\n",
            "Epoch 286/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5331 - accuracy: 0.7362\n",
            "Epoch 287/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5331 - accuracy: 0.7362\n",
            "Epoch 288/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5331 - accuracy: 0.7362\n",
            "Epoch 289/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5331 - accuracy: 0.7358\n",
            "Epoch 290/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5330 - accuracy: 0.7362\n",
            "Epoch 291/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5330 - accuracy: 0.7358\n",
            "Epoch 292/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5329 - accuracy: 0.7365\n",
            "Epoch 293/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5329 - accuracy: 0.7365\n",
            "Epoch 294/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5328 - accuracy: 0.7365\n",
            "Epoch 295/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5328 - accuracy: 0.7367\n",
            "Epoch 296/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5328 - accuracy: 0.7367\n",
            "Epoch 297/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5327 - accuracy: 0.7367\n",
            "Epoch 298/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5327 - accuracy: 0.7366\n",
            "Epoch 299/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5326 - accuracy: 0.7365\n",
            "Epoch 300/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5326 - accuracy: 0.7365\n",
            "Epoch 301/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5326 - accuracy: 0.7365\n",
            "Epoch 302/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5325 - accuracy: 0.7363\n",
            "Epoch 303/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5325 - accuracy: 0.7361\n",
            "Epoch 304/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5325 - accuracy: 0.7365\n",
            "Epoch 305/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5324 - accuracy: 0.7363\n",
            "Epoch 306/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5324 - accuracy: 0.7365\n",
            "Epoch 307/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5324 - accuracy: 0.7367\n",
            "Epoch 308/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5323 - accuracy: 0.7370\n",
            "Epoch 309/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5323 - accuracy: 0.7370\n",
            "Epoch 310/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5323 - accuracy: 0.7367\n",
            "Epoch 311/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5323 - accuracy: 0.7367\n",
            "Epoch 312/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5322 - accuracy: 0.7367\n",
            "Epoch 313/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5322 - accuracy: 0.7366\n",
            "Epoch 314/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5322 - accuracy: 0.7366\n",
            "Epoch 315/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5321 - accuracy: 0.7369\n",
            "Epoch 316/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5321 - accuracy: 0.7366\n",
            "Epoch 317/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5321 - accuracy: 0.7369\n",
            "Epoch 318/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5321 - accuracy: 0.7370\n",
            "Epoch 319/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5320 - accuracy: 0.7369\n",
            "Epoch 320/500\n",
            "7403/7403 [==============================] - 0s 13us/step - loss: 0.5320 - accuracy: 0.7371\n",
            "Epoch 321/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5320 - accuracy: 0.7369\n",
            "Epoch 322/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5320 - accuracy: 0.7369\n",
            "Epoch 323/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5319 - accuracy: 0.7371\n",
            "Epoch 324/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5319 - accuracy: 0.7373\n",
            "Epoch 325/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5319 - accuracy: 0.7371\n",
            "Epoch 326/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5319 - accuracy: 0.7367\n",
            "Epoch 327/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5318 - accuracy: 0.7362\n",
            "Epoch 328/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5318 - accuracy: 0.7361\n",
            "Epoch 329/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5318 - accuracy: 0.7362\n",
            "Epoch 330/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5318 - accuracy: 0.7363\n",
            "Epoch 331/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5318 - accuracy: 0.7362\n",
            "Epoch 332/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5317 - accuracy: 0.7365\n",
            "Epoch 333/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5317 - accuracy: 0.7359\n",
            "Epoch 334/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5317 - accuracy: 0.7363\n",
            "Epoch 335/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5317 - accuracy: 0.7361\n",
            "Epoch 336/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5317 - accuracy: 0.7361\n",
            "Epoch 337/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5316 - accuracy: 0.7359\n",
            "Epoch 338/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5316 - accuracy: 0.7362\n",
            "Epoch 339/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5316 - accuracy: 0.7363\n",
            "Epoch 340/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5316 - accuracy: 0.7361\n",
            "Epoch 341/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5316 - accuracy: 0.7362\n",
            "Epoch 342/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5315 - accuracy: 0.7356\n",
            "Epoch 343/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5315 - accuracy: 0.7358\n",
            "Epoch 344/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5315 - accuracy: 0.7356\n",
            "Epoch 345/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5315 - accuracy: 0.7356\n",
            "Epoch 346/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5315 - accuracy: 0.7358\n",
            "Epoch 347/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5315 - accuracy: 0.7354\n",
            "Epoch 348/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5315 - accuracy: 0.7355\n",
            "Epoch 349/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5314 - accuracy: 0.7356\n",
            "Epoch 350/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5314 - accuracy: 0.7356\n",
            "Epoch 351/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5314 - accuracy: 0.7352\n",
            "Epoch 352/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5314 - accuracy: 0.7352\n",
            "Epoch 353/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5314 - accuracy: 0.7351\n",
            "Epoch 354/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5314 - accuracy: 0.7354\n",
            "Epoch 355/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5314 - accuracy: 0.7354\n",
            "Epoch 356/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5313 - accuracy: 0.7352\n",
            "Epoch 357/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5313 - accuracy: 0.7355\n",
            "Epoch 358/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5313 - accuracy: 0.7354\n",
            "Epoch 359/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5313 - accuracy: 0.7354\n",
            "Epoch 360/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5313 - accuracy: 0.7355\n",
            "Epoch 361/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5313 - accuracy: 0.7355\n",
            "Epoch 362/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5313 - accuracy: 0.7356\n",
            "Epoch 363/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5312 - accuracy: 0.7358\n",
            "Epoch 364/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5312 - accuracy: 0.7361\n",
            "Epoch 365/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5312 - accuracy: 0.7361\n",
            "Epoch 366/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5312 - accuracy: 0.7361\n",
            "Epoch 367/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5312 - accuracy: 0.7361\n",
            "Epoch 368/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5312 - accuracy: 0.7359\n",
            "Epoch 369/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5312 - accuracy: 0.7361\n",
            "Epoch 370/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5312 - accuracy: 0.7361\n",
            "Epoch 371/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5311 - accuracy: 0.7361\n",
            "Epoch 372/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5311 - accuracy: 0.7362\n",
            "Epoch 373/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5311 - accuracy: 0.7361\n",
            "Epoch 374/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5311 - accuracy: 0.7362\n",
            "Epoch 375/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5311 - accuracy: 0.7361\n",
            "Epoch 376/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5311 - accuracy: 0.7358\n",
            "Epoch 377/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5311 - accuracy: 0.7358\n",
            "Epoch 378/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5311 - accuracy: 0.7359\n",
            "Epoch 379/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5310 - accuracy: 0.7356\n",
            "Epoch 380/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5310 - accuracy: 0.7358\n",
            "Epoch 381/500\n",
            "7403/7403 [==============================] - 0s 13us/step - loss: 0.5310 - accuracy: 0.7355\n",
            "Epoch 382/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5310 - accuracy: 0.7355\n",
            "Epoch 383/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5310 - accuracy: 0.7356\n",
            "Epoch 384/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5310 - accuracy: 0.7356\n",
            "Epoch 385/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5310 - accuracy: 0.7355\n",
            "Epoch 386/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5310 - accuracy: 0.7355\n",
            "Epoch 387/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5310 - accuracy: 0.7356\n",
            "Epoch 388/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5310 - accuracy: 0.7356\n",
            "Epoch 389/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5309 - accuracy: 0.7356\n",
            "Epoch 390/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5309 - accuracy: 0.7356\n",
            "Epoch 391/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5309 - accuracy: 0.7358\n",
            "Epoch 392/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5309 - accuracy: 0.7355\n",
            "Epoch 393/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5309 - accuracy: 0.7358\n",
            "Epoch 394/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5309 - accuracy: 0.7356\n",
            "Epoch 395/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5309 - accuracy: 0.7358\n",
            "Epoch 396/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5308 - accuracy: 0.7355\n",
            "Epoch 397/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5308 - accuracy: 0.7352\n",
            "Epoch 398/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5308 - accuracy: 0.7352\n",
            "Epoch 399/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5308 - accuracy: 0.7352\n",
            "Epoch 400/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5308 - accuracy: 0.7351\n",
            "Epoch 401/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5308 - accuracy: 0.7351\n",
            "Epoch 402/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5308 - accuracy: 0.7354\n",
            "Epoch 403/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5308 - accuracy: 0.7354\n",
            "Epoch 404/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5308 - accuracy: 0.7355\n",
            "Epoch 405/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5308 - accuracy: 0.7355\n",
            "Epoch 406/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5308 - accuracy: 0.7355\n",
            "Epoch 407/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5307 - accuracy: 0.7356\n",
            "Epoch 408/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5307 - accuracy: 0.7355\n",
            "Epoch 409/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5307 - accuracy: 0.7355\n",
            "Epoch 410/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5307 - accuracy: 0.7358\n",
            "Epoch 411/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5307 - accuracy: 0.7356\n",
            "Epoch 412/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5307 - accuracy: 0.7356\n",
            "Epoch 413/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5307 - accuracy: 0.7356\n",
            "Epoch 414/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5307 - accuracy: 0.7355\n",
            "Epoch 415/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5307 - accuracy: 0.7355\n",
            "Epoch 416/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5307 - accuracy: 0.7355\n",
            "Epoch 417/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5307 - accuracy: 0.7355\n",
            "Epoch 418/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5306 - accuracy: 0.7361\n",
            "Epoch 419/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5306 - accuracy: 0.7358\n",
            "Epoch 420/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5306 - accuracy: 0.7362\n",
            "Epoch 421/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5306 - accuracy: 0.7362\n",
            "Epoch 422/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5306 - accuracy: 0.7361\n",
            "Epoch 423/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5306 - accuracy: 0.7362\n",
            "Epoch 424/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5306 - accuracy: 0.7362\n",
            "Epoch 425/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5306 - accuracy: 0.7365\n",
            "Epoch 426/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5306 - accuracy: 0.7362\n",
            "Epoch 427/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5306 - accuracy: 0.7365\n",
            "Epoch 428/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5305 - accuracy: 0.7367\n",
            "Epoch 429/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5305 - accuracy: 0.7365\n",
            "Epoch 430/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5305 - accuracy: 0.7365\n",
            "Epoch 431/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5305 - accuracy: 0.7366\n",
            "Epoch 432/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5305 - accuracy: 0.7367\n",
            "Epoch 433/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5305 - accuracy: 0.7365\n",
            "Epoch 434/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5305 - accuracy: 0.7365\n",
            "Epoch 435/500\n",
            "7403/7403 [==============================] - 0s 13us/step - loss: 0.5305 - accuracy: 0.7366\n",
            "Epoch 436/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5304 - accuracy: 0.7366\n",
            "Epoch 437/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5304 - accuracy: 0.7366\n",
            "Epoch 438/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5304 - accuracy: 0.7366\n",
            "Epoch 439/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5304 - accuracy: 0.7369\n",
            "Epoch 440/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5304 - accuracy: 0.7367\n",
            "Epoch 441/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5304 - accuracy: 0.7369\n",
            "Epoch 442/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5304 - accuracy: 0.7369\n",
            "Epoch 443/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5304 - accuracy: 0.7367\n",
            "Epoch 444/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5303 - accuracy: 0.7369\n",
            "Epoch 445/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5303 - accuracy: 0.7367\n",
            "Epoch 446/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5303 - accuracy: 0.7367\n",
            "Epoch 447/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5303 - accuracy: 0.7367\n",
            "Epoch 448/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5303 - accuracy: 0.7367\n",
            "Epoch 449/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5303 - accuracy: 0.7367\n",
            "Epoch 450/500\n",
            "7403/7403 [==============================] - 0s 13us/step - loss: 0.5303 - accuracy: 0.7367\n",
            "Epoch 451/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5302 - accuracy: 0.7371\n",
            "Epoch 452/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5302 - accuracy: 0.7367\n",
            "Epoch 453/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5302 - accuracy: 0.7367\n",
            "Epoch 454/500\n",
            "7403/7403 [==============================] - 0s 13us/step - loss: 0.5302 - accuracy: 0.7373\n",
            "Epoch 455/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5302 - accuracy: 0.7374\n",
            "Epoch 456/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5302 - accuracy: 0.7373\n",
            "Epoch 457/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5302 - accuracy: 0.7371\n",
            "Epoch 458/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5301 - accuracy: 0.7373\n",
            "Epoch 459/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5301 - accuracy: 0.7371\n",
            "Epoch 460/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5301 - accuracy: 0.7369\n",
            "Epoch 461/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5301 - accuracy: 0.7373\n",
            "Epoch 462/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5301 - accuracy: 0.7373\n",
            "Epoch 463/500\n",
            "7403/7403 [==============================] - 0s 13us/step - loss: 0.5301 - accuracy: 0.7373\n",
            "Epoch 464/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5300 - accuracy: 0.7371\n",
            "Epoch 465/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5300 - accuracy: 0.7371\n",
            "Epoch 466/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5300 - accuracy: 0.7371\n",
            "Epoch 467/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5300 - accuracy: 0.7370\n",
            "Epoch 468/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5300 - accuracy: 0.7370\n",
            "Epoch 469/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5300 - accuracy: 0.7367\n",
            "Epoch 470/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5300 - accuracy: 0.7370\n",
            "Epoch 471/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5300 - accuracy: 0.7370\n",
            "Epoch 472/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5299 - accuracy: 0.7371\n",
            "Epoch 473/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5299 - accuracy: 0.7370\n",
            "Epoch 474/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5299 - accuracy: 0.7369\n",
            "Epoch 475/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5299 - accuracy: 0.7370\n",
            "Epoch 476/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5299 - accuracy: 0.7370\n",
            "Epoch 477/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5299 - accuracy: 0.7371\n",
            "Epoch 478/500\n",
            "7403/7403 [==============================] - 0s 9us/step - loss: 0.5299 - accuracy: 0.7374\n",
            "Epoch 479/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5299 - accuracy: 0.7375\n",
            "Epoch 480/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5299 - accuracy: 0.7370\n",
            "Epoch 481/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5299 - accuracy: 0.7370\n",
            "Epoch 482/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5299 - accuracy: 0.7375\n",
            "Epoch 483/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5298 - accuracy: 0.7374\n",
            "Epoch 484/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5298 - accuracy: 0.7371\n",
            "Epoch 485/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5298 - accuracy: 0.7373\n",
            "Epoch 486/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5298 - accuracy: 0.7371\n",
            "Epoch 487/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5298 - accuracy: 0.7370\n",
            "Epoch 488/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5298 - accuracy: 0.7369\n",
            "Epoch 489/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5298 - accuracy: 0.7369\n",
            "Epoch 490/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5298 - accuracy: 0.7371\n",
            "Epoch 491/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5298 - accuracy: 0.7374\n",
            "Epoch 492/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5297 - accuracy: 0.7375\n",
            "Epoch 493/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5297 - accuracy: 0.7375\n",
            "Epoch 494/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5297 - accuracy: 0.7373\n",
            "Epoch 495/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5297 - accuracy: 0.7375\n",
            "Epoch 496/500\n",
            "7403/7403 [==============================] - 0s 12us/step - loss: 0.5297 - accuracy: 0.7375\n",
            "Epoch 497/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5297 - accuracy: 0.7381\n",
            "Epoch 498/500\n",
            "7403/7403 [==============================] - 0s 11us/step - loss: 0.5297 - accuracy: 0.7377\n",
            "Epoch 499/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5297 - accuracy: 0.7379\n",
            "Epoch 500/500\n",
            "7403/7403 [==============================] - 0s 10us/step - loss: 0.5297 - accuracy: 0.7381\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7efed8bd57d0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "execution_count": 26
    },
    {
      "cell_type": "code",
      "source": "score = nn.evaluate(xn_test, y_test_b, verbose=0) #Compute test set accuracy\nprint('Test accuracy:', score[1])",
      "metadata": {
        "id": "6-xaaVX0Rwqx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1637764026511,
          "user_tz": 0,
          "elapsed": 227,
          "user": {
            "displayName": "Epaminondas Kapetanios",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4GwAvDdKDidbsCsl9_jIJUxWhpw38t2VmMVy_Q=s64",
            "userId": "17565203717351331319"
          }
        },
        "outputId": "6b94a989-1046-45ff-d887-1dc74c362587"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.7200161814689636\n"
          ]
        }
      ],
      "execution_count": 27
    },
    {
      "cell_type": "code",
      "source": "p_test = nn.predict_classes(xn_test) # Use trained neural network to predict test points\np_test = p_test.reshape((p_test.shape[0],1))",
      "metadata": {
        "id": "lMqzZRrNRwqx",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1637764029574,
          "user_tz": 0,
          "elapsed": 236,
          "user": {
            "displayName": "Epaminondas Kapetanios",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4GwAvDdKDidbsCsl9_jIJUxWhpw38t2VmMVy_Q=s64",
            "userId": "17565203717351331319"
          }
        }
      },
      "outputs": [],
      "execution_count": 28
    },
    {
      "cell_type": "code",
      "source": "# Store (normalized) instances that were predicted as Bad\nz_test = np.hstack((xn_test, p_test)) \nz_test_bad = z_test[z_test[:,-1]==0, :]",
      "metadata": {
        "id": "B-IYvFk7Rwqy",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1637764034760,
          "user_tz": 0,
          "elapsed": 245,
          "user": {
            "displayName": "Epaminondas Kapetanios",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4GwAvDdKDidbsCsl9_jIJUxWhpw38t2VmMVy_Q=s64",
            "userId": "17565203717351331319"
          }
        }
      },
      "outputs": [],
      "execution_count": 29
    },
    {
      "cell_type": "code",
      "source": "print(z_test_bad[8])",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vI5m3WyoRwqz",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1637764037515,
          "user_tz": 0,
          "elapsed": 245,
          "user": {
            "displayName": "Epaminondas Kapetanios",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4GwAvDdKDidbsCsl9_jIJUxWhpw38t2VmMVy_Q=s64",
            "userId": "17565203717351331319"
          }
        },
        "outputId": "4acf5bd1-86c8-42bd-c4df-9f4144917fb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.21276596 -0.35554172 -0.48694517 -0.40501319 -0.32278481 -0.5\n",
            " -0.5         0.36       -0.42771084 -0.05555556  0.16666667 -0.36538462\n",
            " -0.44736842  0.07       -0.5        -0.5        -0.5        -0.20258621\n",
            " -0.2940552  -0.46875    -0.41304348 -0.44444444 -0.07        0.        ]\n"
          ]
        }
      ],
      "execution_count": 30
    },
    {
      "cell_type": "code",
      "source": "# Store (unnormalized) instances that were predicted as Bad\nzun_test = np.hstack((x_test, p_test)) \nzun_test_bad = zun_test[zun_test[:,-1]==0, :]",
      "metadata": {
        "id": "2sjthNgLRwqz",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1637764041512,
          "user_tz": 0,
          "elapsed": 303,
          "user": {
            "displayName": "Epaminondas Kapetanios",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4GwAvDdKDidbsCsl9_jIJUxWhpw38t2VmMVy_Q=s64",
            "userId": "17565203717351331319"
          }
        }
      },
      "outputs": [],
      "execution_count": 31
    },
    {
      "cell_type": "code",
      "source": "print(zun_test_bad[8])",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05vhKhmbRwqz",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1637764046032,
          "user_tz": 0,
          "elapsed": 247,
          "user": {
            "displayName": "Epaminondas Kapetanios",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4GwAvDdKDidbsCsl9_jIJUxWhpw38t2VmMVy_Q=s64",
            "userId": "17565203717351331319"
          }
        },
        "outputId": "efd2f37a-708e-49e5-ca31-0a33c4f0697c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 67 116   5  40  14   0   0  86   6   4   6  14   1  57   0   0   0  69\n",
            "  97   1   2   1  43   0]\n"
          ]
        }
      ],
      "execution_count": 32
    },
    {
      "cell_type": "code",
      "source": "idx = 8\n\nX = xn_test[idx].reshape((1,) + xn_test[8].shape)\n\n# attach the prediction made by the model to X\nX = np.hstack((X, nn.predict_classes(X).reshape((1,1))))",
      "metadata": {
        "id": "j77Brzt4Rwqz",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1637764049558,
          "user_tz": 0,
          "elapsed": 355,
          "user": {
            "displayName": "Epaminondas Kapetanios",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4GwAvDdKDidbsCsl9_jIJUxWhpw38t2VmMVy_Q=s64",
            "userId": "17565203717351331319"
          }
        }
      },
      "outputs": [],
      "execution_count": 33
    },
    {
      "cell_type": "code",
      "source": "explainer = ProtodashExplainer()\n(W, S, setValues) = explainer.explain(X, z_test_bad, m=5) # Return weights W, Prototypes S and objective function values",
      "metadata": {
        "id": "5_upm6fTRwqz",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1637764053378,
          "user_tz": 0,
          "elapsed": 240,
          "user": {
            "displayName": "Epaminondas Kapetanios",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4GwAvDdKDidbsCsl9_jIJUxWhpw38t2VmMVy_Q=s64",
            "userId": "17565203717351331319"
          }
        }
      },
      "outputs": [],
      "execution_count": 34
    },
    {
      "cell_type": "code",
      "source": "dfs = pd.DataFrame.from_records(zun_test[S, 0:-1].astype('double'))\nRP=[]\nfor i in range(S.shape[0]):\n    RP.append(class_names[int(z_test[S[i], -1])]) # Append class names\ndfs[23] = RP\ndfs.columns = df.columns  \ndfs[\"Weight\"] = np.around(W, 5)/np.sum(np.around(W, 5)) # Calculate normalized importance weights\ndfs.transpose()",
      "metadata": {
        "id": "yKXRiljdRwq0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1637764057359,
          "user_tz": 0,
          "elapsed": 229,
          "user": {
            "displayName": "Epaminondas Kapetanios",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4GwAvDdKDidbsCsl9_jIJUxWhpw38t2VmMVy_Q=s64",
            "userId": "17565203717351331319"
          }
        },
        "outputId": "ee3ef0ec-c301-4638-8e83-a63fe631bc68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ExternalRiskEstimate</th>\n",
              "      <td>81</td>\n",
              "      <td>65</td>\n",
              "      <td>76</td>\n",
              "      <td>85</td>\n",
              "      <td>93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSinceOldestTradeOpen</th>\n",
              "      <td>216</td>\n",
              "      <td>37</td>\n",
              "      <td>282</td>\n",
              "      <td>263</td>\n",
              "      <td>399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSinceMostRecentTradeOpen</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AverageMInFile</th>\n",
              "      <td>84</td>\n",
              "      <td>20</td>\n",
              "      <td>64</td>\n",
              "      <td>96</td>\n",
              "      <td>174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumSatisfactoryTrades</th>\n",
              "      <td>25</td>\n",
              "      <td>16</td>\n",
              "      <td>39</td>\n",
              "      <td>29</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumTrades60Ever2DerogPubRec</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumTrades90Ever2DerogPubRec</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PercentTradesNeverDelq</th>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSinceMostRecentDelq</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MaxDelq2PublicRecLast12M</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MaxDelqEver</th>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumTotalTrades</th>\n",
              "      <td>35</td>\n",
              "      <td>16</td>\n",
              "      <td>40</td>\n",
              "      <td>30</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumTradesOpeninLast12M</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PercentInstallTrades</th>\n",
              "      <td>35</td>\n",
              "      <td>44</td>\n",
              "      <td>28</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSinceMostRecentInqexcl7days</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumInqLast6M</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumInqLast6Mexcl7days</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NetFractionRevolvingBurden</th>\n",
              "      <td>0</td>\n",
              "      <td>58</td>\n",
              "      <td>14</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NetFractionInstallBurden</th>\n",
              "      <td>0</td>\n",
              "      <td>84</td>\n",
              "      <td>86</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumRevolvingTradesWBalance</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumInstallTradesWBalance</th>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumBank2NatlTradesWHighUtilization</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PercentTradesWBalance</th>\n",
              "      <td>38</td>\n",
              "      <td>71</td>\n",
              "      <td>44</td>\n",
              "      <td>54</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RiskPerformance</th>\n",
              "      <td>Good</td>\n",
              "      <td>Bad</td>\n",
              "      <td>Good</td>\n",
              "      <td>Good</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Weight</th>\n",
              "      <td>0.56831</td>\n",
              "      <td>0.21614</td>\n",
              "      <td>0.0479898</td>\n",
              "      <td>0.133248</td>\n",
              "      <td>0.0343134</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          0        1          2         3          4\n",
              "ExternalRiskEstimate                     81       65         76        85         93\n",
              "MSinceOldestTradeOpen                   216       37        282       263        399\n",
              "MSinceMostRecentTradeOpen                 0        5          3         2         27\n",
              "AverageMInFile                           84       20         64        96        174\n",
              "NumSatisfactoryTrades                    25       16         39        29          5\n",
              "NumTrades60Ever2DerogPubRec               0        0          0         0          0\n",
              "NumTrades90Ever2DerogPubRec               0        0          0         0          0\n",
              "PercentTradesNeverDelq                  100      100        100       100        100\n",
              "MSinceMostRecentDelq                      0        0          0         0          0\n",
              "MaxDelq2PublicRecLast12M                  7        7          7         7          7\n",
              "MaxDelqEver                               8        8          8         8          8\n",
              "NumTotalTrades                           35       16         40        30          5\n",
              "NumTradesOpeninLast12M                    1        5          3         1          0\n",
              "PercentInstallTrades                     35       44         28        33          0\n",
              "MSinceMostRecentInqexcl7days              1        0          0         1          2\n",
              "NumInqLast6M                              1        0          0         3          1\n",
              "NumInqLast6Mexcl7days                     1        0          0         3          1\n",
              "NetFractionRevolvingBurden                0       58         14         6          0\n",
              "NetFractionInstallBurden                  0       84         86        60          0\n",
              "NumRevolvingTradesWBalance                1        1          6         2          0\n",
              "NumInstallTradesWBalance                  4        3          1         5          0\n",
              "NumBank2NatlTradesWHighUtilization        0        1          2         0          0\n",
              "PercentTradesWBalance                    38       71         44        54          0\n",
              "RiskPerformance                        Good      Bad       Good      Good       Good\n",
              "Weight                              0.56831  0.21614  0.0479898  0.133248  0.0343134"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "execution_count": 35
    },
    {
      "cell_type": "code",
      "source": "z = z_test_bad[S, 0:-1] # Store the prototypes\neps = 1e-10 # Small constant to guard against divide by zero errors\nfwt = np.zeros(z.shape)\nfor i in range (z.shape[0]): # Compute feature similarity for each prototype\n    for j in range(z.shape[1]):\n        fwt[i, j] = np.exp(-1 * abs(X[0, j] - z[i,j])/(np.std(z[:, j])+eps))\n                \n# move wts to a dataframe to display\ndfw = pd.DataFrame.from_records(np.around(fwt.astype('double'), 2))\ndfw.columns = df.columns[:-1]\ndfw.transpose()        ",
      "metadata": {
        "id": "AwvBkJ6oRwq0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1637764066575,
          "user_tz": 0,
          "elapsed": 243,
          "user": {
            "displayName": "Epaminondas Kapetanios",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4GwAvDdKDidbsCsl9_jIJUxWhpw38t2VmMVy_Q=s64",
            "userId": "17565203717351331319"
          }
        },
        "outputId": "10143952-0701-4f5e-b986-ce15ab8e69f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ExternalRiskEstimate</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSinceOldestTradeOpen</th>\n",
              "      <td>0.90</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSinceMostRecentTradeOpen</th>\n",
              "      <td>0.83</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AverageMInFile</th>\n",
              "      <td>0.66</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumSatisfactoryTrades</th>\n",
              "      <td>0.95</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumTrades60Ever2DerogPubRec</th>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.08</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumTrades90Ever2DerogPubRec</th>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.08</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PercentTradesNeverDelq</th>\n",
              "      <td>0.88</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSinceMostRecentDelq</th>\n",
              "      <td>0.66</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MaxDelq2PublicRecLast12M</th>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MaxDelqEver</th>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumTotalTrades</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumTradesOpeninLast12M</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.15</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PercentInstallTrades</th>\n",
              "      <td>0.80</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSinceMostRecentInqexcl7days</th>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.08</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumInqLast6M</th>\n",
              "      <td>0.56</td>\n",
              "      <td>0.10</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumInqLast6Mexcl7days</th>\n",
              "      <td>0.56</td>\n",
              "      <td>0.10</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NetFractionRevolvingBurden</th>\n",
              "      <td>0.20</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NetFractionInstallBurden</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.12</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumRevolvingTradesWBalance</th>\n",
              "      <td>0.90</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumInstallTradesWBalance</th>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumBank2NatlTradesWHighUtilization</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PercentTradesWBalance</th>\n",
              "      <td>0.93</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       0     1     2     3     4\n",
              "ExternalRiskEstimate                0.02  0.01  0.03  0.01  0.00\n",
              "MSinceOldestTradeOpen               0.90  0.26  0.21  0.36  0.73\n",
              "MSinceMostRecentTradeOpen           0.83  0.74  0.10  0.79  0.81\n",
              "AverageMInFile                      0.66  0.11  0.53  0.87  0.57\n",
              "NumSatisfactoryTrades               0.95  0.71  0.36  0.82  0.13\n",
              "NumTrades60Ever2DerogPubRec         1.00  1.00  0.42  0.08  1.00\n",
              "NumTrades90Ever2DerogPubRec         1.00  1.00  1.00  0.08  1.00\n",
              "PercentTradesNeverDelq              0.88  0.92  0.09  0.53  0.79\n",
              "MSinceMostRecentDelq                0.66  0.16  0.79  0.46  0.41\n",
              "MaxDelq2PublicRecLast12M            1.00  1.00  1.00  0.13  0.36\n",
              "MaxDelqEver                         1.00  1.00  0.47  0.22  0.22\n",
              "NumTotalTrades                      1.00  0.66  0.42  0.61  0.13\n",
              "NumTradesOpeninLast12M              1.00  0.15  1.00  0.62  0.09\n",
              "PercentInstallTrades                0.80  1.00  0.61  0.95  0.09\n",
              "MSinceMostRecentInqexcl7days        1.00  1.00  1.00  0.08  1.00\n",
              "NumInqLast6M                        0.56  0.10  1.00  1.00  0.13\n",
              "NumInqLast6Mexcl7days               0.56  0.10  1.00  1.00  0.13\n",
              "NetFractionRevolvingBurden          0.20  0.34  0.90  0.87  0.07\n",
              "NetFractionInstallBurden            1.00  0.12  1.00  1.00  0.15\n",
              "NumRevolvingTradesWBalance          0.90  0.51  0.64  0.90  0.10\n",
              "NumInstallTradesWBalance            1.00  1.00  0.87  0.87  0.09\n",
              "NumBank2NatlTradesWHighUtilization  1.00  0.84  0.84  0.84  0.09\n",
              "PercentTradesWBalance               0.93  0.87  0.13  0.59  0.19"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "execution_count": 36
    },
    {
      "cell_type": "code",
      "source": "# Some interesting user samples to try: 2344 449 1168 1272\nidx = 20\n\nX = xn_test[idx].reshape((1,) + xn_test[idx].shape)\nprint(\"Computing PN for Sample:\", idx)\nprint(\"Prediction made by the model:\", nn.predict_proba(X))\nprint(\"Prediction probabilities:\", class_names[np.argmax(nn.predict_proba(X))])\nprint(\"\")\n\nmymodel = KerasClassifier(nn)\nexplainer = CEMExplainer(mymodel)\n\narg_mode = 'PN' # Find pertinent negatives\narg_max_iter = 1000 # Maximum number of iterations to search for the optimal PN for given parameter settings\narg_init_const = 10.0 # Initial coefficient value for main loss term that encourages class change\narg_b = 9 # No. of updates to the coefficient of the main loss term\narg_kappa = 0.2 # Minimum confidence gap between the PNs (changed) class probability and original class' probability\narg_beta = 1e-1 # Controls sparsity of the solution (L1 loss)\narg_gamma = 100 # Controls how much to adhere to a (optionally trained) auto-encoder\nmy_AE_model = None # Pointer to an auto-encoder\narg_alpha = 0.01 # Penalizes L2 norm of the solution\narg_threshold = 1. # Automatically turn off features <= arg_threshold if arg_threshold < 1\narg_offset = 0.5 # the model assumes classifier trained on data normalized\n                # in [-arg_offset, arg_offset] range, where arg_offset is 0 or 0.5\n# Find PN for applicant 20\n(adv_pn, delta_pn, info_pn) = explainer.explain_instance(X, arg_mode, my_AE_model, arg_kappa, arg_b,\n                                                         arg_max_iter, arg_init_const, arg_beta, arg_gamma,\n                                                            arg_alpha, arg_threshold, arg_offset)",
      "metadata": {
        "id": "7hExopzpRwq1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1637764096335,
          "user_tz": 0,
          "elapsed": 19544,
          "user": {
            "displayName": "Epaminondas Kapetanios",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gij4GwAvDdKDidbsCsl9_jIJUxWhpw38t2VmMVy_Q=s64",
            "userId": "17565203717351331319"
          }
        },
        "outputId": "05c3babb-8ac5-45ac-bc62-9314c119f5e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing PN for Sample: 20\n",
            "Prediction made by the model: [[-0.27522987  0.3882701 ]]\n",
            "Prediction probabilities: Good\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/aix360/algorithms/contrastive/CEM_aen.py:60: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/aix360/algorithms/contrastive/CEM_aen.py:151: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/aix360/algorithms/contrastive/CEM_aen.py:213: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/aix360/algorithms/contrastive/CEM_aen.py:216: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/aix360/algorithms/contrastive/CEM_aen.py:230: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "iter:0 const:[10.]\n",
            "Loss_Overall:0.2178, Loss_Attack:0.0000\n",
            "Loss_L2Dist:0.1298, Loss_L1Dist:0.8797, AE_loss:0.0\n",
            "target_lab_score:-0.7238, max_nontarget_lab_score:0.7904\n",
            "\n",
            "iter:500 const:[10.]\n",
            "Loss_Overall:0.1072, Loss_Attack:0.0000\n",
            "Loss_L2Dist:0.0722, Loss_L1Dist:0.3493, AE_loss:0.0\n",
            "target_lab_score:-0.1423, max_nontarget_lab_score:0.2323\n",
            "\n",
            "iter:0 const:[5.]\n",
            "Loss_Overall:2.6079, Loss_Attack:2.5906\n",
            "Loss_L2Dist:0.0046, Loss_L1Dist:0.1263, AE_loss:0.0\n",
            "target_lab_score:0.2118, max_nontarget_lab_score:-0.1064\n",
            "\n",
            "iter:500 const:[5.]\n",
            "Loss_Overall:0.6564, Loss_Attack:0.5730\n",
            "Loss_L2Dist:0.0591, Loss_L1Dist:0.2431, AE_loss:0.0\n",
            "target_lab_score:0.0069, max_nontarget_lab_score:0.0923\n",
            "\n",
            "iter:0 const:[2.5]\n",
            "Loss_Overall:2.1588, Loss_Attack:2.1588\n",
            "Loss_L2Dist:0.0000, Loss_L1Dist:0.0000, AE_loss:0.0\n",
            "target_lab_score:0.3883, max_nontarget_lab_score:-0.2752\n",
            "\n",
            "iter:500 const:[2.5]\n",
            "Loss_Overall:2.1588, Loss_Attack:2.1588\n",
            "Loss_L2Dist:0.0000, Loss_L1Dist:0.0000, AE_loss:0.0\n",
            "target_lab_score:0.3883, max_nontarget_lab_score:-0.2752\n",
            "\n",
            "iter:0 const:[3.75]\n",
            "Loss_Overall:3.0483, Loss_Attack:3.0464\n",
            "Loss_L2Dist:0.0002, Loss_L1Dist:0.0167, AE_loss:0.0\n",
            "target_lab_score:0.3622, max_nontarget_lab_score:-0.2502\n",
            "\n",
            "iter:500 const:[3.75]\n",
            "Loss_Overall:3.2381, Loss_Attack:3.2381\n",
            "Loss_L2Dist:0.0000, Loss_L1Dist:0.0000, AE_loss:0.0\n",
            "target_lab_score:0.3883, max_nontarget_lab_score:-0.2752\n",
            "\n",
            "iter:0 const:[4.375]\n",
            "Loss_Overall:3.0836, Loss_Attack:3.0766\n",
            "Loss_L2Dist:0.0015, Loss_L1Dist:0.0547, AE_loss:0.0\n",
            "target_lab_score:0.3064, max_nontarget_lab_score:-0.1969\n",
            "\n",
            "iter:500 const:[4.375]\n",
            "Loss_Overall:3.7778, Loss_Attack:3.7778\n",
            "Loss_L2Dist:0.0000, Loss_L1Dist:0.0000, AE_loss:0.0\n",
            "target_lab_score:0.3883, max_nontarget_lab_score:-0.2752\n",
            "\n",
            "iter:0 const:[4.6875]\n",
            "Loss_Overall:2.9080, Loss_Attack:2.8965\n",
            "Loss_L2Dist:0.0028, Loss_L1Dist:0.0870, AE_loss:0.0\n",
            "target_lab_score:0.2628, max_nontarget_lab_score:-0.1551\n",
            "\n",
            "iter:500 const:[4.6875]\n",
            "Loss_Overall:3.7970, Loss_Attack:3.7950\n",
            "Loss_L2Dist:0.0003, Loss_L1Dist:0.0175, AE_loss:0.0\n",
            "target_lab_score:0.3608, max_nontarget_lab_score:-0.2488\n",
            "\n",
            "iter:0 const:[4.53125]\n",
            "Loss_Overall:3.0032, Loss_Attack:2.9940\n",
            "Loss_L2Dist:0.0021, Loss_L1Dist:0.0708, AE_loss:0.0\n",
            "target_lab_score:0.2847, max_nontarget_lab_score:-0.1761\n",
            "\n",
            "iter:500 const:[4.53125]\n",
            "Loss_Overall:3.9127, Loss_Attack:3.9127\n",
            "Loss_L2Dist:0.0000, Loss_L1Dist:0.0000, AE_loss:0.0\n",
            "target_lab_score:0.3883, max_nontarget_lab_score:-0.2752\n",
            "\n",
            "iter:0 const:[4.609375]\n",
            "Loss_Overall:2.9573, Loss_Attack:2.9469\n",
            "Loss_L2Dist:0.0024, Loss_L1Dist:0.0789, AE_loss:0.0\n",
            "target_lab_score:0.2737, max_nontarget_lab_score:-0.1656\n",
            "\n",
            "iter:500 const:[4.609375]\n",
            "Loss_Overall:2.8953, Loss_Attack:2.8815\n",
            "Loss_L2Dist:0.0060, Loss_L1Dist:0.0774, AE_loss:0.0\n",
            "target_lab_score:0.2669, max_nontarget_lab_score:-0.1583\n",
            "\n",
            "iter:0 const:[4.6484375]\n",
            "Loss_Overall:2.9331, Loss_Attack:2.9221\n",
            "Loss_L2Dist:0.0026, Loss_L1Dist:0.0830, AE_loss:0.0\n",
            "target_lab_score:0.2683, max_nontarget_lab_score:-0.1604\n",
            "\n",
            "iter:500 const:[4.6484375]\n",
            "Loss_Overall:3.9410, Loss_Attack:3.9405\n",
            "Loss_L2Dist:0.0000, Loss_L1Dist:0.0051, AE_loss:0.0\n",
            "target_lab_score:0.3802, max_nontarget_lab_score:-0.2675\n",
            "\n"
          ]
        }
      ],
      "execution_count": 37
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "id": "O6HnrLOfRwq1"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}